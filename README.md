# Explainable Reinforcement Learning for Decoded Neurofeedback (DecNef)

This repository contains the implementation of the project described in the work *Towards Explaining Decoded Neurofeedback with Explainable Reinforcement Learning* by Hojjat Azimi Asrari. The project explores integrating Explainable Reinforcement Learning (XRL) techniques into Decoded Neurofeedback (DecNef) studies, employing advanced methods like Denoising Diffusion Policy Optimization (DDPO) to improve interpretability and efficacy.

## Overview

Decoded Neurofeedback (DecNef) is a technique that leverages real-time fMRI data to modulate neural activity patterns unconsciously. While DecNef has demonstrated potential for clinical and cognitive neuroscience applications, its variability and black-box nature pose challenges.

This project introduces a novel integration of reinforcement learning with denoising diffusion models to:
- Model subject-specific brain activity patterns.
- Enhance interpretability using Explainable AI (XAI) principles.
- Improve DecNef efficacy by optimizing training and individual variability handling.

## Features

- **Explainable Reinforcement Learning**: Implementation of XRL to interpret decision-making processes in DecNef.
- **Denoising Diffusion Models**: Application of DDPO to iteratively refine neural activity states.
- **Subject-Specific Training**: Models trained for individual participants to capture personalized neural activity patterns.
- **Closed-Loop Framework**: Integration of feedback mechanisms for real-time optimization.
